# Computation
------------------------------

# ML Compilers to support Frameworks
MLIR dialects
TVM
XLA
PyTorch Glow
cuDNN 

# Frameworks
PyTorch
Tensorflow

# Quantization

# Framework -> IR -> Machine Code
- IRs are generated by compilers. IRs are computation graphs.
- To generate machine code from IR, compiler use codegen. Example of codegen is LLVM. This process in called lowering.
- Tensorflow XLA, NVCC, TVM all use LLVM

# Different types of compilers
-domain specific compiler: NVCC, XLA, PyTorch uses XLA for TPU and Glow for other hardwares.
-3rd party compiler: TVM for custom compiler

MLIR helps build own compiler.

# WASM  (Web Assembly):
Instead of compile to run on a specific hardware. compile it to run on browser (WASM format that can be run with Javascript)
WASM compiler: Emscripten (which also uses LLVM codegen), but it only compiles from C and C++ into WASM. scailable is supposed to convert from scikit-learn models into WASM.
TVM also compiles to WASM.


# Extra
GCC compiles C/C++ code to machine code
LLVM is good for CPU and GPU but MLIR is generate framwework for any hardware. LLVM is a subset of MLIR.
MLIR (A meta compiler that is used to build other compilers), 

# Communication
-----------------------------

# Distributed

- MultiGPU
- Multinode

-------------------------------------------

Triton  + PyTorch + MLIR
Pallas + JAX + XLA

# Resources
- https://www.kapilsharma.dev/posts/deep-dive-into-triton-internals/
- https://www.kapilsharma.dev/posts/deep-dive-into-triton-internals-2/
- https://www.kapilsharma.dev/posts/deep-dive-into-triton-internals-3/

- https://www.youtube.com/watch?v=Oo07fFb-aH0